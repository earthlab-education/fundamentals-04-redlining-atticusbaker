{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0eb4dc23-022c-4b3c-97eb-8c13c90e196c",
   "metadata": {},
   "source": [
    "# STEP 7: Fit a model\n",
    "\n",
    "One way to determine if redlining is related to NDVI is to see if we can\n",
    "correctly predict the redlining grade from the mean NDVI value. With 4\n",
    "categories, we’d expect to be right only about 25% of the time if we\n",
    "guessed the redlining grade at random. Any accuracy greater than 25%\n",
    "indicates that there is a relationship between vegetation health and\n",
    "redlining.\n",
    "\n",
    "To start out, we’ll fit a Decision Tree Classifier to the data. A\n",
    "decision tree is good at splitting data up into squares by setting\n",
    "thresholds. That makes sense for us here, because we’re looking for\n",
    "thresholds in the mean NDVI that indicate a particular redlining grade.\n",
    "\n",
    "First, import variables from previous notebooks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bfd58b22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no stored variable or alias denver_ndvi_stats_gdf\n"
     ]
    }
   ],
   "source": [
    "store -r denver_ndvi_stats_gdf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5a6e603-b9b9-4bac-9626-9b402f240124",
   "metadata": {},
   "source": [
    "<link rel=\"stylesheet\" type=\"text/css\" href=\"./assets/styles.css\"><div class=\"callout callout-style-default callout-titled callout-task\"><div class=\"callout-header\"><div class=\"callout-icon-container\"><i class=\"callout-icon\"></i></div><div class=\"callout-title-container flex-fill\">Try It: Import packages</div></div><div class=\"callout-body-container callout-body\"><p>The cell below imports some functions and classes from the\n",
    "<code>scikit-learn</code> package to help you fit and evaluate a\n",
    "decision tree model on your data. You may need some additional packages\n",
    "later one. Make sure to import them here.</p></div></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8128d1af",
   "metadata": {
    "highlight": true
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "import geopandas as gpd\n",
    "import matplotlib.colors as mcolors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "878dcf08-b82b-4ede-9403-f588d37cf047",
   "metadata": {},
   "source": [
    "As with all models, it is possible to **overfit** our Decision Tree\n",
    "Classifier by splitting the data into too many disconnected rectangles.\n",
    "We could theoretically get 100% accuracy this way, but drawing a\n",
    "rectangle for each individual data point. There are many ways to try to\n",
    "avoid overfitting. In this case, we can limit the **depth** of the\n",
    "decision tree to 2. This means we’ll be drawing 4 rectangles, the same\n",
    "as the number of categories we have.\n",
    "\n",
    "Alternative methods of limiting overfitting include:\n",
    "\n",
    "-   Splitting the data into test and train groups – the overfitted model\n",
    "    is unlikely to fit data it hasn’t seen. In this case, we have\n",
    "    relatively little data compared to the number of categories, and so\n",
    "    it is hard to evaluate a test/train split.\n",
    "-   Pruning the decision tree to maximize accuracy while minimizing\n",
    "    complexity. `scikit-learn` will do this for you automatically. You\n",
    "    can also fit the model at a variety of depths, and look for\n",
    "    diminishing accuracy returns.\n",
    "\n",
    "<link rel=\"stylesheet\" type=\"text/css\" href=\"./assets/styles.css\"><div class=\"callout callout-style-default callout-titled callout-task\"><div class=\"callout-header\"><div class=\"callout-icon-container\"><i class=\"callout-icon\"></i></div><div class=\"callout-title-container flex-fill\">Try It: Fit a tree model</div></div><div class=\"callout-body-container callout-body\"><p>Replace <code>predictor_variables</code> and\n",
    "<code>observed_values</code> with the values you want to use in your\n",
    "model.</p></div></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10c162b6",
   "metadata": {
    "highlight": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'denver_ndvi_stats_gdf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Convert categories to numbers\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m denver_ndvi_stats_gdf[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgrade_codes\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mdenver_ndvi_stats_gdf\u001b[49m\u001b[38;5;241m.\u001b[39mgrade\u001b[38;5;241m.\u001b[39mcat\u001b[38;5;241m.\u001b[39mcodes\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Fit model\u001b[39;00m\n\u001b[0;32m      5\u001b[0m tree_classifier \u001b[38;5;241m=\u001b[39m DecisionTreeClassifier(max_depth\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\u001b[38;5;241m.\u001b[39mfit(\n\u001b[0;32m      6\u001b[0m     predictor_variables,\n\u001b[0;32m      7\u001b[0m     observed_values,\n\u001b[0;32m      8\u001b[0m )\n",
      "\u001b[1;31mNameError\u001b[0m: name 'denver_ndvi_stats_gdf' is not defined"
     ]
    }
   ],
   "source": [
    "# Convert categories to numbers\n",
    "denver_ndvi_stats_gdf['grade_codes'] = denver_ndvi_stats_gdf.grade.cat.codes\n",
    "\n",
    "# Prepare predictor variables and observed values\n",
    "predictor_variables = denver_ndvi_stats_gdf[['mean_ndvi']]\n",
    "observed_values = denver_ndvi_stats_gdf['grade_codes']\n",
    "\n",
    "# Split the data into training and testing sets (70% train, 30% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    predictor_variables, observed_values, test_size=0.3, random_state=42\n",
    ")\n",
    "\n",
    "# Fit model\n",
    "tree_classifier = DecisionTreeClassifier(max_depth=2).fit(\n",
    "    predictor_variables,\n",
    "    observed_values,\n",
    ")\n",
    "\n",
    "# Visualize tree\n",
    "plot_tree(tree_classifier)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b29427a3-8a7f-4634-ba02-cf58fe3021ab",
   "metadata": {},
   "source": [
    "<link rel=\"stylesheet\" type=\"text/css\" href=\"./assets/styles.css\"><div class=\"callout callout-style-default callout-titled callout-task\"><div class=\"callout-header\"><div class=\"callout-icon-container\"><i class=\"callout-icon\"></i></div><div class=\"callout-title-container flex-fill\">Try It: Plot model results</div></div><div class=\"callout-body-container callout-body\"><p>Create a plot of the results by:</p>\n",
    "<ol type=\"1\">\n",
    "<li>Predict grades for each region using the <code>.predict()</code>\n",
    "method of your <code>DecisionTreeClassifier</code>.</li>\n",
    "<li>Subtract the actual grades from the predicted grades</li>\n",
    "<li>Plot the calculated prediction errors as a chloropleth.</li>\n",
    "</ol></div></div>\n",
    "\n",
    "One method of evaluating your model’s accuracy is by cross-validation.\n",
    "This involves selecting some of your data at random, fitting the model,\n",
    "and then testing the model on a different group. Cross-validation gives\n",
    "you a range of potential accuracies using a subset of your data. It also\n",
    "has a couple of advantages, including:\n",
    "\n",
    "1.  It’s good at identifying overfitting, because it tests on a\n",
    "    different set of data than it trains on.\n",
    "2.  You can use cross-validation on any model, unlike statistics like\n",
    "    $p$-values and $R^2$ that you may have used in the past.\n",
    "\n",
    "A disadvantage of cross-validation is that with smaller datasets like\n",
    "this one, it is easy to end up with splits that are too small to be\n",
    "meaningful, or don’t have all the categories.\n",
    "\n",
    "Remember – anything above 25% is better than random!\n",
    "\n",
    "<link rel=\"stylesheet\" type=\"text/css\" href=\"./assets/styles.css\"><div class=\"callout callout-style-default callout-titled callout-task\"><div class=\"callout-header\"><div class=\"callout-icon-container\"><i class=\"callout-icon\"></i></div><div class=\"callout-title-container flex-fill\">Try It: Evaluate the model</div></div><div class=\"callout-body-container callout-body\"><p>Use cross-validation with the <code>cross_val_score</code> to\n",
    "evaluate your model. Start out with the <code>'balanced_accuracy'</code>\n",
    "scoring method, and 4 cross-validation groups.</p></div></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03274512",
   "metadata": {
    "highlight": true
   },
   "outputs": [],
   "source": [
    "denver_ndvi_gdf['predicted_grade'] = clf.predict(predictor_variables)\n",
    "\n",
    "denver_ndvi_gdf['prediction_error'] = denver_ndvi_gdf['predicted_grade'] - denver_ndvi_gdf['redlining_grade']\n",
    "\n",
    "# Ensure the GeoDataFrame is compatible for plotting\n",
    "denver_ndvi_gdf = gpd.GeoDataFrame(denver_ndvi_gdf)\n",
    "\n",
    "# Create the plot\n",
    "def plot_choropleth(gdf, column, title, cmap='coolwarm'):\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(12, 8))\n",
    "    gdf.plot(column=column, ax=ax, legend=True, cmap=cmap,\n",
    "             legend_kwds={'label': \"Prediction Error\",\n",
    "                          'orientation': \"vertical\"})\n",
    "    ax.set_title(title)\n",
    "    plt.show()\n",
    "plot_choropleth(denver_ndvi_gdf, 'prediction_error', \"Prediction Errors as a Choropleth\")\n",
    "\n",
    "# Evaluate the model with cross-validation\n",
    "cross_val_scores=cross_val_score(clf,x_train,y_train,cv=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "322e1b7b-7205-4776-aae3-dcc3b068977f",
   "metadata": {},
   "source": [
    "<link rel=\"stylesheet\" type=\"text/css\" href=\"./assets/styles.css\"><div class=\"callout callout-style-default callout-titled callout-extra\"><div class=\"callout-header\"><div class=\"callout-icon-container\"><i class=\"callout-icon\"></i></div><div class=\"callout-title-container flex-fill\">Looking for an Extra Challenge?: Fit and evaluate an alternative model</div></div><div class=\"callout-body-container callout-body\"><p>Try out some other models and/or hyperparameters (e.g. changing the\n",
    "max_depth). What do you notice?</p></div></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b2387dd1",
   "metadata": {
    "highlight": true
   },
   "outputs": [],
   "source": [
    "# Try another model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89b80a8f-a63f-4ed8-9a20-51bb771a6bab",
   "metadata": {},
   "source": [
    "<link rel=\"stylesheet\" type=\"text/css\" href=\"./assets/styles.css\"><div class=\"callout callout-style-default callout-titled callout-respond\"><div class=\"callout-header\"><div class=\"callout-icon-container\"><i class=\"callout-icon\"></i></div><div class=\"callout-title-container flex-fill\">Reflect and Respond</div></div><div class=\"callout-body-container callout-body\"><p>Practice writing about your model. In a few sentences, explain your\n",
    "methods, including some advantages and disadvantages of the choice.\n",
    "Then, report back on your results. Does your model indicate that\n",
    "vegetation health in a neighborhood is related to its redlining\n",
    "grade?</p></div></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5286e179-8b3f-488d-889a-70829ae9cbaf",
   "metadata": {},
   "source": [
    "# YOUR MODEL DESCRIPTION AND EVALUATION HERE\n",
    "\n",
    "The methods above detail the relationship between vegetation health (measured as NDVI) and historical redlining grades in neighborhoods in denver, colorado. A decision tree is used for its ability to handle non-linear relationships between data. Because zonalstats could not import to my kernel without issue, interpretations of this relationship are purely speculative from here. Advantages to using a decision tree model include the fact that they are very interpretable, and able to use strange, non-linear data. Unfortunately, decision trees can easily overfit data, lowering predictability accuracy for any new data, but at the same time could also miss relationships if it does not have enough depth. The data scientist's job is to acheive a healthy balance between over and underfitting. I am assuming that the model would output some relationship between health of greenery and redlining grades. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
